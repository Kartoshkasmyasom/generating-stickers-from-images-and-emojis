{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmlVXxQAD8y3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import *\n",
        "import random\n",
        "from PIL import Image\n",
        "import traceback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NE86ZsaBVUT"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "cuda = torch.device('cuda:1')\n",
        "transform_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-TNPoLfBV2u",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# !unzip downloaded.zip -d BigData\n",
        "import glob\n",
        "\n",
        "files = glob.glob(\"BigData/downloaded/*/*.webp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woLCbx4RFLtd"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"BigData/downloaded/metadata.pkl\", \"rb\") as metadata:\n",
        "    emojies = pickle.load(metadata)\n",
        "for key, value in emojies.items():\n",
        "    lst = []\n",
        "\n",
        "    for _, value_im in value.items():\n",
        "        lst.append(value_im[\"emoji\"])\n",
        "\n",
        "    emojies[key] = lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA1LWd-Qs77L"
      },
      "outputs": [],
      "source": [
        "unique_emojies = []\n",
        "for key in emojies:\n",
        "    unique_emojies.extend(emojies[key])\n",
        "unique_emojies = list(set(unique_emojies))\n",
        "\n",
        "emoji_id = {}\n",
        "for i in range(len(unique_emojies)):\n",
        "    emoji_id[unique_emojies[i]] = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IitfmV3n2xq7"
      },
      "outputs": [],
      "source": [
        "# pairs=[]\n",
        "# for stickerpack,pics in emojies.items():\n",
        "#   for link in files:\n",
        "#     s = '/' + stickerpack + '/'\n",
        "#     if s in link:\n",
        "#       id_ = int(link[link.rfind('/') + 1:link.rfind('.')])\n",
        "#       pairs.append((link,emoji_id[pics[id_]]))\n",
        "\n",
        "all_stickerpacks = {}\n",
        "link_emoji_stickerpack = []\n",
        "for stickerpack, pics in emojies.items():\n",
        "\n",
        "    all_stickerpacks[stickerpack] = []\n",
        "\n",
        "    for link in files:\n",
        "        s = '/' + stickerpack + '/'\n",
        "        if s in link:\n",
        "            id_ = int(link[link.rfind('/') + 1:link.rfind('.')])\n",
        "            all_stickerpacks[stickerpack].append((link, emoji_id[pics[id_]]))\n",
        "            link_emoji_stickerpack.append((link, emoji_id[pics[id_]], stickerpack))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drw4s3HjrlJu"
      },
      "outputs": [],
      "source": [
        "def transform_img_cv2(link):  # РАБОАТЕТ преобразуем ссылки в картинки\n",
        "\n",
        "    img = cv2.imread(link, cv2.IMREAD_UNCHANGED)  # открываем картинку\n",
        "\n",
        "    # resize image\n",
        "    resized = cv2.resize(img, (transform_size, transform_size), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    img_array = np.array(resized, dtype=\"float32\")  # переводим картинку в np\n",
        "    img = torch.from_numpy(img_array)  # tensor\n",
        "    if img.size()[2] != 4:\n",
        "        mask = torch.zeros(transform_size, transform_size, 4)  # mask\n",
        "        mask[:, :, :img.size()[2]] = img\n",
        "        img = mask\n",
        "    img = torch.permute(img, (2, 0, 1))  # переставляем канал на первую позицию\n",
        "\n",
        "    return img / 255  # возвращаем тенсор размера в батч"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpCoBM6FIHgb"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.X = x\n",
        "        self.Y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        link, label_encode, label_decode = self.X[index]\n",
        "        return transform_img_cv2(link), label_encode, label_decode, transform_img_cv2(self.Y[index])\n",
        "\n",
        "class NewDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.X = x\n",
        "        self.Y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.Y[index]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x67ovSLj-ogS",
        "outputId": "45dd8e35-458b-4a9d-b02c-99e9a34e662f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ATTENTION: write YY if you HAVE MORE 12 GB RAM to rewrite data or Y to download data or just skip\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            " Y\n"
          ]
        }
      ],
      "source": [
        "print(\"ATTENTION: write YY if you HAVE MORE 12 GB RAM to rewrite data or Y to download data or just skip\")\n",
        "input_ = input()\n",
        "if \"Y\" in input_:\n",
        "    if \"YY\" in input_:\n",
        "        data_to_save_x = []\n",
        "        data_to_save_y = []\n",
        "\n",
        "        for picture, emoji_i, stickerpack in link_emoji_stickerpack:\n",
        "            picture1, emoji_i1 = random.choice(all_stickerpacks[stickerpack])\n",
        "\n",
        "            data_to_save_x.append((transform_img_cv2(picture), emoji_i, emoji_i1))\n",
        "            data_to_save_y.append(transform_img_cv2(picture1))\n",
        "\n",
        "        data = NewDataset(data_to_save_x, data_to_save_y)\n",
        "        with open(\"BigData/data.pkl\", \"wb\") as save_data:\n",
        "            pickle.dump(data, save_data)\n",
        "\n",
        "    with open(\"BigData/data.pkl\", \"rb\") as data_load:\n",
        "        data_load = pickle.load(data_load)\n",
        "        data_loader = torch.utils.data.DataLoader(data_load, batch_size=batch_size, shuffle=True)\n",
        "else:\n",
        "\n",
        "    data_x = []\n",
        "    data_y = []\n",
        "    for picture, emoji_i, stickerpack in link_emoji_stickerpack:\n",
        "        picture1, emoji_i1 = random.choice(all_stickerpacks[stickerpack])\n",
        "\n",
        "        data_x.append((picture, emoji_i, emoji_i1))\n",
        "        data_y.append(picture1)\n",
        "\n",
        "    data = MyDataset(data_x, data_y)\n",
        "    data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlIEBe3frb8l"
      },
      "source": [
        "#МОДЕЛь\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf-IW15wD5vn"
      },
      "outputs": [],
      "source": [
        "class Autoencoder_Working(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.embeddings = nn.Embedding(len(unique_emojies), 64)\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(68, 16, 3, stride=2, padding=1),  # 64\n",
        "            nn.InstanceNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 64, 3, stride=2, padding=1),  # 32\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 256, 3, stride=2, padding=1),  # 16\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 1024, 3, stride=2, padding=1),  # 8\n",
        "            nn.InstanceNorm2d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(1024, 4096, 3, stride=2, padding=1),  # 4\n",
        "            nn.InstanceNorm2d(4096),\n",
        "            nn.Conv2d(4096, 4096, 3, stride=2, padding=1),  # 2\n",
        "            nn.InstanceNorm2d(4096)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(2048 + 64, 4096, 4, stride=2, padding=1),  # 4\n",
        "            nn.InstanceNorm2d(4096),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(4096, 1024, 4, stride=2, padding=1),  # 8\n",
        "            nn.InstanceNorm2d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(1024, 256, 4, stride=2, padding=1),  # 16\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(256, 32, 4, stride=2, padding=1),  # 32\n",
        "            nn.InstanceNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 8, 4, stride=2, padding=1),  # 64\n",
        "            nn.InstanceNorm2d(8),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(8, 4, 4, stride=2, padding=1),  # (n,4,128,128)\n",
        "            nn.InstanceNorm2d(4),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def Encoder_func(self, x, label_encode):\n",
        "        label_encode = label_encode.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, x.shape[2], x.shape[3])\n",
        "        x = torch.cat([x, label_encode], 1)\n",
        "\n",
        "        encoded = self.encoder(x)  # свертка\n",
        "\n",
        "        return encoded\n",
        "\n",
        "    def Decoder_func(self, x, label_decode):\n",
        "        label_decode = label_decode.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, x.shape[2], x.shape[3])\n",
        "        x = torch.cat([x, label_decode], 1)\n",
        "        decoded = self.decoder(x)\n",
        "\n",
        "        return decoded\n",
        "\n",
        "    def _sample_latent(self, h_enc):\n",
        "        mu = h_enc[:, :2048]\n",
        "        log_sigma = h_enc[:, 2048:]\n",
        "        sigma = torch.exp(log_sigma)\n",
        "\n",
        "        return mu + sigma * torch.randn_like(sigma), mu, sigma  # Reparameterization trick\n",
        "\n",
        "    def latent_loss(self, mu, sigma):\n",
        "        mean_sq = mu ** 2\n",
        "        stddev_sq = sigma ** 2\n",
        "        return 0.5 * torch.mean(mean_sq + stddev_sq - torch.log(stddev_sq) - 1)\n",
        "\n",
        "    def forward(self, tensor, label_encode, label_decode):\n",
        "        label_encode, label_decode = torch.tensor(label_encode, dtype=torch.long), torch.tensor(label_decode,\n",
        "                                                                                                dtype=torch.long)\n",
        "\n",
        "        # КОДИРОВНИЕ\n",
        "        encoded = self.Encoder_func(tensor, self.embeddings(label_encode))\n",
        "        # print(encoded.size())\n",
        "\n",
        "        # LOSS\n",
        "        encoded, mu, sigma = self._sample_latent(encoded)\n",
        "        loss = self.latent_loss(mu, sigma)\n",
        "\n",
        "        # ДЕКОДИРОВАНИЕ\n",
        "        decoded = self.Decoder_func(encoded, self.embeddings(label_decode))\n",
        "        # print(decoded.size())\n",
        "        return decoded, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21ksBM6gX8nU",
        "outputId": "92d1386d-f962-4e26-a2dd-e774cf06e875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ATTENTION: write Y if you want to rewrite model else just skip or any symbol\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            " Y\n"
          ]
        }
      ],
      "source": [
        "print(\"ATTENTION: write Y if you want to rewrite model else just skip or any symbol\")\n",
        "input_ = input()\n",
        "if input_ == \"Y\":\n",
        "    model = Autoencoder_Working().to(cuda)\n",
        "else:\n",
        "    with open(\"BigData/model.pkl\", \"rb\") as md:\n",
        "        model = pickle.load(md)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "1cuBmUoWMgMV",
        "outputId": "439ba08a-f336-4ea1-b799-6470ca4e18e6",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-3cb793381d81>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print(sum(p.numel() for p in model.parameters())\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m '(' was never closed\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "outputs = []\n",
        "try:\n",
        "    for epoch in range(num_epochs):\n",
        "        for tensor, label_encode, label_decode, y in tqdm(data_loader):\n",
        "            tensor, label_encode, label_decode, y = tensor.to(cuda), label_encode.to(cuda), label_decode.to(cuda), y.to(\n",
        "                cuda)\n",
        "            recon, loss_kld = model(tensor, label_encode, label_decode)\n",
        "            loss_rec = criterion(recon, y)\n",
        "            loss = loss_rec + loss_kld\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'Epoch:{epoch + 1}, Loss:{loss.item():.4f}')\n",
        "        outputs.append(loss.item())\n",
        "\n",
        "        # сохр МОдели\n",
        "        with open(\"BigData/model.pkl\", \"wb\") as md:\n",
        "            pickle.dump(model, md)\n",
        "\n",
        "        # ---- картинки ----\n",
        "        _, axarr = plt.subplots(1, 2)\n",
        "\n",
        "        resized = cv2.resize(recon[-1].permute(1, 2, 0).cpu().detach().numpy(), (512, 512),\n",
        "                             interpolation=cv2.INTER_AREA)\n",
        "        axarr[0].imshow(resized)\n",
        "        axarr[1].imshow(y[-1].permute(1, 2, 0).cpu().detach().numpy())\n",
        "\n",
        "except Exception as e:\n",
        "print('FATAL ERROR:\\n', traceback.format_exc())\n",
        "print(\"FATAL ERROR\")\n",
        "\n",
        "# dataset_shuffle\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(range(len(outputs)), outputs)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEvO6g__LhfX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "with open(\"BigData/model.pkl\", \"wb\") as md:\n",
        "    pickle.dump(model, md)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jolPGR4O-oga"
      },
      "outputs": [],
      "source": [
        "def make_stickers(x, y, z):\n",
        "    with open(\"BigData/model.pkl\", \"wb\") as md:\n",
        "        model = pickle.load(md)\n",
        "    img_tensor = model(x, y, z)\n",
        "    resized = cv2.resize(img_tensor.permute(1, 2, 0).cpu().detach().numpy(), (512, 512), interpolation=cv2.INTER_AREA)\n",
        "    print(dtype(resized))\n",
        "    return 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "gTTTgzSf3UHu"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}